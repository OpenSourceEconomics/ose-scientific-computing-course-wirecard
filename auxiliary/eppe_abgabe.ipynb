{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project for the course in effective-programming-practices for economists | Winter 21/22, M.Sc. Economics, Bonn University |\n",
    "<br><br>\n",
    "the project is created by:<br><br>\n",
    "[Daniel Nogues Kollert](https://github.com/johqniel) (Student-ID: 3055726)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Global Optimization Algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documentes the work done by myself within the final project for the \"OSE - scientific computing for economists\" class that was held by Prof. Eisenhauer in the Wintersemester 21/22. The project was handed in by two students but only one (Daniel Nogues Kollert) is handing in his work for grading to the \"effective programming practises for economists\" to. They just decided to extend their work a little bit by missing pieces that were done by their co-author. The work presented in this notebook is inpired to a great extent by the following Articles:\n",
    "\n",
    "> Arnoud, Antoine and Guvenen, Fatih and Kleineberg, Tatjana, Benchmarking Global Optimizers (October 2019)<br><br>\n",
    "\n",
    "> Beiranvand, V., Hare, W. & Lucet, Y. Best practices for comparing optimization algorithms. Optim Eng 18, 815–848 (2017)<br><br>\n",
    "\n",
    "> Bartz-Beielstein, T. et al. Benchmarking in Optimization: Best Practice and Open Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Benchmarking-Global-Optimization-Algorithms\" data-toc-modified-id=\"Benchmarking-Global-Optimization-Algorithms-1\">Benchmarking Global Optimization Algorithms\n",
    "\n",
    "</a></span></li><li><span><a href=\"#1.-Introduction\" data-toc-modified-id=\"1.-Goal-of-our-project-2\">1. Goal of our project\n",
    "\n",
    "</a></span></li><li><span><a href=\"#2.-Global-Optimization\" data-toc-modified-id=\"2.-Global-Optimization-3\">2. What is \"global optimization\"?\n",
    "\n",
    "</a></span></li><li><span><a href=\"#3.-Optimization-Algorithms\" data-toc-modified-id=\"3.-Optimization-Algorithms-4\">3. Some optimization Algorithms we implemeted.\n",
    "\n",
    "</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Gradient-Based-Algorithms\" data-toc-modified-id=\"3.1-Gradient-Based-Algorithms-4.1\">3.1 Gradient based algorithm\n",
    "\n",
    "</a></span></li><li><span><a href=\"#3.2-Derivative-Free-Algorithms\" data-toc-modified-id=\"3.2-Derivative-Free-Algorithms-4.2\">3.2 Derivative-free algorithms\n",
    "\n",
    "</a></span></li></ul></li><li><span><a href=\"#4.-Test-Problems\" data-toc-modified-id=\"4.-Test-Problems-5\">4. Test Problems\n",
    "\n",
    "\n",
    "</a></span></li></ul></li><li><span><a href=\"#5.-Benchmarking-Procedure\" data-toc-modified-id=\"5.-Benchmarking-Procedure-6\">5. Benchmarking Procedure</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1-Testing-of-optimization-Algorithms\" data-toc-modified-id=\"5.1-Testing-of-optimization-Algorithms-6.1\">5.1 Testing of optimization Algorithms</a></span></li><li><span><a href=\"#5.2-Performing-Benchmarking-Experiments\" data-toc-modified-id=\"5.2-Performing-Benchmarking-Experiments-6.2\">5.2 Performing Benchmarking Experiments</a></span></li><li><span><a href=\"#5.3-Algorithm-Performance-Measures\" data-toc-modified-id=\"5.3-Algorithm-Performance-Measures-6.3\">5.3 Algorithm Performance Measures</a></span></li><li><span><a href=\"#5.4-Reporting-Results\" data-toc-modified-id=\"5.4-Reporting-Results-6.4\">5.4 Reporting Results</a></span></li><li><span><a href=\"#5.5-Specific-Approach-of-this-Study\" data-toc-modified-id=\"5.5-Specific-Approach-of-this-Study-6.5\">5.5 Specific Approach of this Study</a></span></li></ul></li><li><span><a href=\"#6.-Results\" data-toc-modified-id=\"6.-Results-7\">6. Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.1-Griewank-Function\" data-toc-modified-id=\"6.1-Griewank-Function-7.1\">6.1 Griewank Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.1.1-Data-Profiles\" data-toc-modified-id=\"6.1.1-Data-Profiles-7.1.1\">6.1.1 Data-Profiles</a></span></li><li><span><a href=\"#6.1.2-Deviation-Profiles\" data-toc-modified-id=\"6.1.2-Deviation-Profiles-7.1.2\">6.1.2 Deviation-Profiles</a></span></li></ul></li><li><span><a href=\"#6.2-Rastrigin-Function\" data-toc-modified-id=\"6.2-Rastrigin-Function-7.2\">6.2 Rastrigin Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.2.1-Data-Profiles\" data-toc-modified-id=\"6.2.1-Data-Profiles-7.2.1\">6.2.1 Data-Profiles</a></span></li><li><span><a href=\"#6.2.2-Deviation-Profiles\" data-toc-modified-id=\"6.2.2-Deviation-Profiles-7.2.2\">6.2.2 Deviation-Profiles</a></span></li></ul></li><li><span><a href=\"#6.3-Levi-Function\" data-toc-modified-id=\"6.3-Levi-Function-7.3\">6.3 Levi Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.3.1-Data-Profiles\" data-toc-modified-id=\"6.3.1-Data-Profiles-7.3.1\">6.3.1 Data-Profiles</a></span></li><li><span><a href=\"#6.3.2-Deviation-Profiles\" data-toc-modified-id=\"6.3.2-Deviation-Profiles-7.3.2\">6.3.2 Deviation-Profiles</a></span></li></ul></li><li><span><a href=\"#6.4-Rosenbrock-Function\" data-toc-modified-id=\"6.4-Rosenbrock-Function-7.4\">6.4 Rosenbrock Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.4.1-Data-Profiles\" data-toc-modified-id=\"6.4.1-Data-Profiles-7.4.1\">6.4.1 Data-Profiles</a></span></li><li><span><a href=\"#6.4.2-Deviation-Profiles\" data-toc-modified-id=\"6.4.2-Deviation-Profiles-7.4.2\">6.4.2 Deviation-Profiles</a></span></li></ul></li><li><span><a href=\"#6.5-Performance-Profiles\" data-toc-modified-id=\"6.5-Performance-Profiles-7.5\">6.5 Performance Profiles</a></span></li></ul></li><li><span><a href=\"#7.-Extension-of-the-Suite-of-Test-Problems\" data-toc-modified-id=\"7.-Extension-of-the-Suite-of-Test-Problems-8\">7. Extension of the Suite of Test Problems</a></span></li><li><span><a href=\"#7.1-Ackley-Function\" data-toc-modified-id=\"7.1-Ackley-Function-9\">7.1 Ackley Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.1.1-Data-Profiles\" data-toc-modified-id=\"7.1.1-Data-Profiles-9.1\">7.1.1 Data Profiles</a></span></li><li><span><a href=\"#7.1.1-Deviation-Profiles\" data-toc-modified-id=\"7.1.1-Deviation-Profiles-9.2\">7.1.1 Deviation Profiles</a></span></li></ul></li><li><span><a href=\"#7.2-Zakharov-Function\" data-toc-modified-id=\"7.2-Zakharov-Function-10\">7.2 Zakharov Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.2.2-Data-Profiles\" data-toc-modified-id=\"7.2.2-Data-Profiles-10.1\">7.2.2 Data-Profiles</a></span></li><li><span><a href=\"#7.2.3-Deviation-Profiles\" data-toc-modified-id=\"7.2.3-Deviation-Profiles-10.2\">7.2.3 Deviation-Profiles</a></span></li></ul></li><li><span><a href=\"#7.3-Easom-Function\" data-toc-modified-id=\"7.3-Easom-Function-11\">7.3 Easom Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.3.1-Data-Profiles\" data-toc-modified-id=\"7.3.1-Data-Profiles-11.1\">7.3.1 Data Profiles</a></span></li><li><span><a href=\"#7.3.2-Deviation-Profiles\" data-toc-modified-id=\"7.3.2-Deviation-Profiles-11.2\">7.3.2 Deviation Profiles</a></span></li></ul></li><li><span><a href=\"#8.-Critical-Assessment\" data-toc-modified-id=\"8.-Critical-Assessment-12\">8. Critical Assessment</a></span></li><li><span><a href=\"#9.-Extension:-Economic-Application\" data-toc-modified-id=\"9.-Extension:-Economic-Application-13\">9. Extension: Economic Application</a></span><ul class=\"toc-item\"><li><span><a href=\"#9.1-Results:-Data-Profiles\" data-toc-modified-id=\"9.1-Results:-Data-Profiles-13.1\">9.1 Results: Data-Profiles</a></span></li></ul></li><li><span><a href=\"#10.-Conclusion\" data-toc-modified-id=\"10.-Conclusion-14\">10. Conclusion</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-15\">References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Goal of our project \n",
    "---\n",
    "\n",
    "The goal of our project was to benchmark multiple global optimization algorithms from the **NLOPT** libary. This part of our work mostly replicates work done in Gueven et al. (2019). We wanted to extend on their article by implementing our own optimization algorithms and compare them to the ones provided by the python libaries. Sadly we struggled to implement them flexible and robust enough to run the benchmarks designed for the algorithms from the **NLOPT** libary. In a future project that extend our work one could try to further improve the two algorithms we implemented but for now we decided to benchmark them with a second benchmark routine. While we can thus not compare them directly to the algorithms from the **NLOPT** libary we still get to compare the two to one another. The work we submitted to the OSE class is documented in the File student_project.ipynb . In this notebook we will mostly describe the work done in the skripts newton_based_optimization.py, nelder_mead_based_optimization.py, test_optimization.py, callable_algorithms.py and benchmark_routine.py since these were all done exclusivly by me and illustrate well how I applied routines learned in the EPPE class such as using Git, pytest and docstrings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. What is \"global optimization\"? \n",
    "---\n",
    "\n",
    "Global optimization is a term that includes many different mathematical problems of varying complexity and abstraction. Within this notebook though we want to restrict ourselfes to the unconstrained optimization of real valued functions whose domain is a open ball within $\\R^n$. We make these restrictions because the two optimization algorithms we implemented can not yet deal with any constrains and do only take open balls as domains. Clearly these restrictions make the algorithms inpractical for professional use. Since in the benchmark methodology outlined in Guvenen et al. (2019) they controll the functions to be optimized, these restrictions are reasonable. Mathematically the problems we consider can be described by the following: \n",
    "\n",
    "Let $f\\colon \\R^n \\to \\R$ be a real valued function, $r\\in\\R_+$ a positive real number and $\\mathbf{x}_\\text{d}$ be a point in $\\R^n$ such that:\n",
    "\n",
    "$$ \\underset{|x-\\mathbf{x}_\\text{d}|\\leq r}{\\text{argmin}}(f) \\in \\text{B}_r(\\mathbf{x}_\\text{d}).$$\n",
    "\n",
    "Here $\\text{B}_r(\\mathbf{x}_\\text{d})$ denotes the open circle with radius $r$ around $\\mathbf{x}_\\text{d}$.\n",
    "\n",
    "Then the algorithms should find: \n",
    "\n",
    "$$\\underset{|x-\\mathbf{x}_\\text{d}|\\leq r}{\\text{argmin}}(f).$$\n",
    "\n",
    "Since one of the two optimization algorithms we implemented relies on first and second derivatives we assume furthermore that $f$ is twice continuously differentiable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Some optimization algorithms we implemented\n",
    "---\n",
    "\n",
    "We implemented two optimization algorithms. First we implemented an algorithm that relies on the Newton-Method an algorithm that can find roots of continuously differentiable functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.1 Gradient based algorithm\n",
    "---\n",
    "The algorithm we designed relies on the following mathematical results: \n",
    "\n",
    "\n",
    "- A continuously differentiable function has a critical point wherever it has global minimum. \n",
    "- If the newton method applied to the continuously differentiable function $f'$ converges to a point $x$ this point is a root of $f'$.\n",
    "\n",
    "\n",
    "By one we get that the set of critical points of a function is a set of candidates for the global minimum of a function. Once we have the set of critical points of $f$ within its domain we can simply take the smallest and have a good guess for the global extremum. Two provides us with a strategy to find these critical points. We can run the newton method from different starting points within the domain. Each time it converges we get a candidate that we can add to our list of candidates. \n",
    "\n",
    "We will not provide pseudo-code for the newton method but a verbal explication: It aims to find the roots of a function. We use the fact that the gradients of a function $\\nabla f (\\mathbf{x})$ tell us whether we are moving up or down if we move in the direction of $\\mathbf{x}$. Thus we can use the gradient as source of information about the curvature of the function. We can start at some point $\\mathbf{x_n}$ and solve in each iteration for the direction $\\mathbf{y}$ with the steepest slope. In our next iteration we then consider \n",
    "\n",
    "$$\\mathbf{x_{n+1}}:= \\mathbf{x_n} + \\epsilon \\cdot \\mathbf{y},$$ \n",
    "\n",
    "where $\\epsilon$ is some small number. Though this approach is very intuitive it comes with a few drawbacks. For example it is not easy to implement and costly since it requieres solving linear equations. Furthermore as explained before gradient based routines fail at optimizing discrete functions or functions with discontinuity points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2 Derivative-free algorithm\n",
    "---\n",
    "\n",
    "As the name suggest this class comprises all sorts of optimization algorithms that do not use derivatives of the function to be optimized. It is difficult to give an general idea how it works, since there are many different approaches. An interesting pattern is that often times these algorithms are inspired by nature or other real life phenomena. For example there is an optimization algorithm inspired by imperialistic competition (E. Atashpaz-Gargari and C. Lucas, 2007) and discrete optimization algorithms are inspired by the behaviour of bees (D.T. Pham, 2005) and ants (A. Colorni, M. Dorigo and V. Maniezzo 1991).\n",
    "\n",
    "A well known gradient free algorithm for non discrete functions is the nelder-mead algorithm. It simulates a simplex that moves around the graph of the function until it finds a candidate for a global optimum. We implemented a version of this algorithm. It is way less intuitive than the Newton-Method and thus we are not providing pseudo code because it would not be more insightfull than the commented python-code. We still provide a brief overview of it's key ideas:\n",
    "\n",
    "**NELDER-MEAD SIMPLEX ALGORITHM**\n",
    "\n",
    "The Nelder-Mead-method (Nelder, Mead 1965) is the second optimization algorithm that we implemented ourselfes. It generated a simplex around the starting point and then checks how its verticies are horizontally distributed on the surface of the function to be optimized. Depending on how they are the simplex wanders arounds the function by reflecting its highest verticy contracting the highest verticy inside of the simplex or shrinking the whole symplex towards the lowest verticy of the simplex.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Test Problems\n",
    "---\n",
    "\n",
    "In order to test the algorithms we implemented we needed to select real valued functions to be optimized. To test the algorithms from the **NLOPT** libary we selected established testfunctions that are challenging to optimize. According to Guvenen et al. (2019) 4 such problems are given by the following: \n",
    "\n",
    "- Griewank Function \n",
    "- Rastrigin Function \n",
    "- Levi Function \n",
    "- Rosenbrock Function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.1 Griewank Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.2 Rastrigin Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.3 Levi Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.4 Rosenbrock Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Benchmarking Procedure\n",
    "---\n",
    "\n",
    "Most benchmarking studies have a clear underlying reason, why the study is conducted. For example in Guvenen et al. (2019) the reason for benchmarking has been the introduction of a new optimization routine (the TIK TAK) algorithm. The primary goal of this study has been to show the value of this novel algorithm compared to more classical methods. \n",
    "\n",
    "Our primary goals for the replication of their study were to:\n",
    "\n",
    "1. Gather experience on how to design and implement a benchmarking study \n",
    "2. Gather experience in designing and implementing flexible optimization algorithnms\n",
    "3. Find out how well our self-implemented optimization algorithms perform compared to the **NLOPT** libary\n",
    "\n",
    "In the following chapters we are going to walk through different steps we followed to reach our third goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.1 Testing of optimization Algorithms\n",
    "---\n",
    "\n",
    "Once we figured out which inputs the optimization algorithms we want to implement would have we designed a test routine with pytest to verify wether the functions we use for the optimization work properly. All the tests are provided in the File called test_optimization.py (in the auxiliarry foulder) in which we test the two algorithms with 6 functions. The first three are functions with only a few local minima. Both algorithms can also find the optimum of the rosenbrock, rastrigin and griewank function, if they start the iteration close enough to the actual optimum. The first three functions are given by the following equations: \n",
    "\n",
    "\\begin{align*}\n",
    "    &\\bullet \\hspace{0.3cm}\\mathbf{x} \\mapsto 20 \\cdot (x_1 + x_2)^2 + x_2^4 + 1, \\\\\n",
    "    &\\bullet \\hspace{0.3cm}\\mathbf{x}\\mapsto\\frac{1}{200} \\cdot (x_1 + 1)^2 \\cdot \\{\\text{cos}(x_2) + 1\\} + x_2^2,\\\\\n",
    "    &\\bullet \\hspace{0.3cm}\\mathbf{x}\\mapsto\\frac{1}{800}\\cdot(x_1 - 6)^4 \\cdot \\{\\text{sin}(x_2) + 3\\} + x_2^4.\n",
    "\\end{align*}\n",
    "\n",
    "All these functions are bowlshaped and have minima at: $(0,0)^T,(-1,0)^T,(6,0)^T \\in \\mathbb{R}^2$ respectively. Our test routines test_call_nelder_mead and test_old_newton_opti are designed such that they through an error **iff** one of the two optimization algorithms does not find the correct optimum for one of the six functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nelder_mead_based_optimization_source'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7136\\2797711947.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mauxiliary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_optimization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtest_call_nelder_mead_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_old_newton_opti\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_call_nelder_mead_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_old_newton_opti\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Daniel\\Desktop\\Studium\\Git_WS_22\\ose-scientific-computing-course-wirecard\\auxiliary\\test_optimization.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m from nelder_mead_based_optimization_source import (\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0minitial_simplex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mcall_nelder_mead_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nelder_mead_based_optimization_source'"
     ]
    }
   ],
   "source": [
    "from auxiliary.test_optimization import test_call_nelder_mead_method, test_old_newton_opti\n",
    "\n",
    "test_call_nelder_mead_method()\n",
    "test_old_newton_opti()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this is only a small selection of test functions it shows that for easy problems the optimization algorithms we implemented work properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.2 Performing Benchmarking Experiments\n",
    "---\n",
    "\n",
    "While benchmarking the optimization algorithms we obtained from libaries we realized that the naive implementations of both the nelder-mead method as well as the newton based do not perform fast and reliable enough for the benchmarking procedure we designed for the **NLOPT** libaries algorithms. The benchmarking would not finish in a reasonable time and both algorithms are very likely to loose themselves in local minima. Thus they were only identifying the correct minimum if they either start the optimization very close to the actual global minimum or if the function to be optimized has only one local (and global) minimum. Thus we decided to exclude them from the Benchmarking for now. Still we learned a lot about the implementation of optimization algorithms and learned on what to improve on for future optimization projects. \n",
    "\n",
    "While polishing our project for the assignment for the EPPE class, we implemented a simple benchmarking routine that allows us to benchmark at least one of the two algorithms we implemented: the nelder-mead based optimization. The results will be disscussed in the end of this notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.3 Algorithm Performance Measures\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.4 Reporting Results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.5 Specific Approach of this Study\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.1 Griewank Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.1.1 Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.1.2 Deviation-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.2 Rastrigin Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.2.1 Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.2.2 Deviation-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.3 Levi Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.3.1 Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.3.2 Deviation-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.4 Rosenbrock Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.4.1 Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.4.2 Deviation-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. Extension of the Suite of Test Problems\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.1 Ackley Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.1.1 Deviation Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.2 Zakharov Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.2.2 Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.2.3 Deviation-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.3 Easom Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.3.1 Data Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.3.2 Deviation Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Critical Assessment\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 9. Extension: Economic Application\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9.1 Results: Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 10. Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  References\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pardalos, Panos M.; Romeijn, Edwin H., \"Handbook of Global Optimization\", Springer Science and Business Media, 2013\n",
    "- Liberti, Leo. “Introduction to Global Optimization.”, Computer Science, (2006)\n",
    "- Ali, Montaz, Charoenchai Khompatraporn, and Zelda B. Zabinsky, “A Numerical\n",
    "  Evaluation of Several Stochastic Algorithms on Selected Continuous Global Optimization\n",
    "  Test Problems,” Journal of Global Optimization, 2005, 31, 635–672.\n",
    "- Surjanovic, S. & Bingham, D. (2013). Virtual Library of Simulation Experiments: Test Functions and Datasets.     Retrieved January 4, 2022, from http://www.sfu.ca/~ssurjano.\n",
    "- Jamil, M., & Yang, X. (2013). A literature survey of benchmark functions for global optimisation problems. Int. J. Math. Model. Numer. Optimisation, 4, 150-194.\n",
    "- Griewank A.O. (1981), Generalized descent for global optimization,Journal of Optimization Theoryand Applications34, 11-39\n",
    "- Locatelli, M. A Note on the Griewank Test Function. Journal of Global Optimization 25, 169–174 (2003). https://doi.org/10.1023/A:1021956306041\n",
    "- Rosenbrock, H.H. (1960). \"An automatic method for finding the greatest or least value of a function\". The Computer Journal. 3 (3): 175–184. doi:10.1093/comjnl/3.3.175. ISSN 0010-4620.\n",
    "- J. J. More', B. S. Garbow, and K. E. Hillstrom. Testing unconstrained optimization\n",
    "   software. ACM Transactions on Mathematical Software (TOMS),7(1):17{41, March 1981\n",
    "   \n",
    "- Steven G. Johnson, The NLopt nonlinear-optimization package [link](http://github.com/stevengj/nlopt)\n",
    "- Dolan, Elizabeth D. and Jorge Moré, “Benchmarking Optimization Software with Performance\n",
    "  Profiles,” Mathematical Programming, 2002, 91 (2), 201–213.\n",
    "- Moré, Jorge J. and Stefan M. Wild, “Benchmarking Derivative-Free Optimization Algorithms,”\n",
    "  SIAM Journal on Optimization, 2009, 20 (1), 172–191.\n",
    "\n",
    "- Price, Wyn L., “A controlled random search procedure for global optimisation,” The Computer\n",
    "  Journal, 1977, 20 (4), 367–370.\n",
    "  \n",
    "- Kaelo, P. and M. M. Ali, “Some variants of the controlled random search algorithm for global\n",
    "  optimization,” Journal of Optimization Theory and Applications, 2006, 130 (2), 253–264.\n",
    "  \n",
    "- Runarsson, Thomas P. and Xin Yao, “Stochastic ranking for constrained evolutionary\n",
    "  optimization,” IEEE Transactions on evolutionary computation, 2000, 4 (3), 284–294.\n",
    "  \n",
    "- Rinnooy Kan, Alexander and G. T. Timmer, “Stochastic Global Optimization Methods,\n",
    "  Part I, Clustering Methods,” Mathematic Programming, 1987, 39 (27-56).\n",
    "  \n",
    "- Silva-Santos, Carlos Henrique, Marcos Sergio Goncalves, and Hugo Enrique\n",
    "  Hernandez-Figueroa, “Designing novel photonic devices by bio-inspired computing,” IEEE\n",
    "  Photonics Technology Letters, 2010, 22 (15), 1177–1179.\n",
    "\n",
    "- E. Atashpaz-Gargari and C. Lucas, \"Imperialist competitive algorithm: An algorithm for optimization inspired by imperialistic competition,\" 2007 IEEE Congress on   \n",
    "  Evolutionary Computation, 2007, pp. 4661-4667, doi: 10.1109/CEC.2007.4425083.\n",
    "\n",
    "- Alberto Colorni, Marco Dorigo and Vittorio Maniezzo. \"Distributed optimization by ant colonies.\" Proceedings of the first European conference on artificial life.    \n",
    "  Vol.142. 1991\n",
    "  \n",
    "- Markowitz, H. (1952), PORTFOLIO SELECTION*. The Journal of Finance, 7: 77-91. https://doi.org/10.1111/j.1540-6261.1952.tb01525.x\n",
    "\n",
    "- Eric Zivot Lecture Materials [see here](https://faculty.washington.edu/ezivot/classes.htm)\n",
    "\n",
    "- Liu, Scott and Xu, Rong, The Effects of Risk Aversion on Optimization, February 2010 (February 22, 2010). MSCI Barra Research Paper No. 2010-06, Available at SSRN: https://ssrn.com/abstract=1601412 or http://dx.doi.org/10.2139/ssrn.1601412\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
