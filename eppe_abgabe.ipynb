{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project for the course in effective-programming-practices for economists | Winter 21/22, M.Sc. Economics, Bonn University |\n",
    "<br><br>\n",
    "the project is created by:<br><br>\n",
    "[Daniel Nogues Kollert](https://github.com/johqniel) (Student-ID: 3055726)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Global Optimization Algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documentes the work done by myself within the final project for the \"OSE - scientific computing for economists\" class that was held by Prof. Eisenhauer in the Wintersemester 21/22. The project was handed in by two students but only one (Daniel Nogues Kollert) is handing in his work for grading to the \"effective programming practises for economists\" to. They just decided to extend their work a little bit by missing pieces that were done by their co-author. The work presented in this notebook is inpired to a great extent by the following Articles:\n",
    "\n",
    "> Arnoud, Antoine and Guvenen, Fatih and Kleineberg, Tatjana, Benchmarking Global Optimizers (October 2019)<br><br>\n",
    "\n",
    "> Beiranvand, V., Hare, W. & Lucet, Y. Best practices for comparing optimization algorithms. Optim Eng 18, 815–848 (2017)<br><br>\n",
    "\n",
    "> Bartz-Beielstein, T. et al. Benchmarking in Optimization: Best Practice and Open Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Benchmarking-Global-Optimization-Algorithms\" data-toc-modified-id=\"Benchmarking-Global-Optimization-Algorithms-1\">Benchmarking Global Optimization Algorithms\n",
    "\n",
    "</a></span></li><li><span><a href=\"#1.-Introduction\" data-toc-modified-id=\"1.-Goal-of-our-project-2\">1. Goal of our project\n",
    "\n",
    "</a></span></li><li><span><a href=\"#2.-Global-Optimization\" data-toc-modified-id=\"2.-Global-Optimization-3\">2. What is \"global optimization\"?\n",
    "\n",
    "</a></span></li><li><span><a href=\"#3.-Optimization-Algorithms\" data-toc-modified-id=\"3.-Optimization-Algorithms-4\">3. Some optimization Algorithms we implemeted.\n",
    "\n",
    "</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Gradient-Based-Algorithms\" data-toc-modified-id=\"3.1-Gradient-Based-Algorithms-4.1\">3.1 Gradient Based Algorithms\n",
    "\n",
    "</a></span></li><li><span><a href=\"#3.2-Derivative-Free-Algorithms\" data-toc-modified-id=\"3.2-Derivative-Free-Algorithms-4.2\">3.2 Derivative-Free Algorithms\n",
    "\n",
    "</a></span></li></ul></li><li><span><a href=\"#4.-Test-Problems\" data-toc-modified-id=\"4.-Test-Problems-5\">4. Test Problems\n",
    "\n",
    "\n",
    "</a></span></li></ul></li><li><span><a href=\"#5.-Benchmarking-Procedure\" data-toc-modified-id=\"5.-Benchmarking-Procedure-6\">5. Benchmarking Procedure</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1-Testing-of-optimization-Algorithms\" data-toc-modified-id=\"5.1-Testing-of-optimization-Algorithms-6.1\">5.1 Testing of optimization Algorithms</a></span></li><li><span><a href=\"#5.2-Performing-Benchmarking-Experiments\" data-toc-modified-id=\"5.2-Performing-Benchmarking-Experiments-6.2\">5.2 Performing Benchmarking Experiments</a></span></li><li><span><a href=\"#5.3-Algorithm-Performance-Measures\" data-toc-modified-id=\"5.3-Algorithm-Performance-Measures-6.3\">5.3 Algorithm Performance Measures</a></span></li><li><span><a href=\"#5.4-Reporting-Results\" data-toc-modified-id=\"5.4-Reporting-Results-6.4\">5.4 Reporting Results</a></span></li><li><span><a href=\"#5.5-Specific-Approach-of-this-Study\" data-toc-modified-id=\"5.5-Specific-Approach-of-this-Study-6.5\">5.5 Specific Approach of this Study</a></span></li></ul></li><li><span><a href=\"#6.-Results\" data-toc-modified-id=\"6.-Results-7\">6. Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.1-Griewank-Function\" data-toc-modified-id=\"6.1-Griewank-Function-7.1\">6.1 Griewank Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.1.1-Data-Profiles\" data-toc-modified-id=\"6.1.1-Data-Profiles-7.1.1\">6.1.1 Data-Profiles</a></span></li><li><span><a href=\"#6.1.2-Deviation-Profiles\" data-toc-modified-id=\"6.1.2-Deviation-Profiles-7.1.2\">6.1.2 Deviation-Profiles</a></span></li></ul></li><li><span><a href=\"#6.2-Rastrigin-Function\" data-toc-modified-id=\"6.2-Rastrigin-Function-7.2\">6.2 Rastrigin Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.2.1-Data-Profiles\" data-toc-modified-id=\"6.2.1-Data-Profiles-7.2.1\">6.2.1 Data-Profiles</a></span></li><li><span><a href=\"#6.2.2-Deviation-Profiles\" data-toc-modified-id=\"6.2.2-Deviation-Profiles-7.2.2\">6.2.2 Deviation-Profiles</a></span></li></ul></li><li><span><a href=\"#6.3-Levi-Function\" data-toc-modified-id=\"6.3-Levi-Function-7.3\">6.3 Levi Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.3.1-Data-Profiles\" data-toc-modified-id=\"6.3.1-Data-Profiles-7.3.1\">6.3.1 Data-Profiles</a></span></li><li><span><a href=\"#6.3.2-Deviation-Profiles\" data-toc-modified-id=\"6.3.2-Deviation-Profiles-7.3.2\">6.3.2 Deviation-Profiles</a></span></li></ul></li><li><span><a href=\"#6.4-Rosenbrock-Function\" data-toc-modified-id=\"6.4-Rosenbrock-Function-7.4\">6.4 Rosenbrock Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.4.1-Data-Profiles\" data-toc-modified-id=\"6.4.1-Data-Profiles-7.4.1\">6.4.1 Data-Profiles</a></span></li><li><span><a href=\"#6.4.2-Deviation-Profiles\" data-toc-modified-id=\"6.4.2-Deviation-Profiles-7.4.2\">6.4.2 Deviation-Profiles</a></span></li></ul></li><li><span><a href=\"#6.5-Performance-Profiles\" data-toc-modified-id=\"6.5-Performance-Profiles-7.5\">6.5 Performance Profiles</a></span></li></ul></li><li><span><a href=\"#7.-Extension-of-the-Suite-of-Test-Problems\" data-toc-modified-id=\"7.-Extension-of-the-Suite-of-Test-Problems-8\">7. Extension of the Suite of Test Problems</a></span></li><li><span><a href=\"#7.1-Ackley-Function\" data-toc-modified-id=\"7.1-Ackley-Function-9\">7.1 Ackley Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.1.1-Data-Profiles\" data-toc-modified-id=\"7.1.1-Data-Profiles-9.1\">7.1.1 Data Profiles</a></span></li><li><span><a href=\"#7.1.1-Deviation-Profiles\" data-toc-modified-id=\"7.1.1-Deviation-Profiles-9.2\">7.1.1 Deviation Profiles</a></span></li></ul></li><li><span><a href=\"#7.2-Zakharov-Function\" data-toc-modified-id=\"7.2-Zakharov-Function-10\">7.2 Zakharov Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.2.2-Data-Profiles\" data-toc-modified-id=\"7.2.2-Data-Profiles-10.1\">7.2.2 Data-Profiles</a></span></li><li><span><a href=\"#7.2.3-Deviation-Profiles\" data-toc-modified-id=\"7.2.3-Deviation-Profiles-10.2\">7.2.3 Deviation-Profiles</a></span></li></ul></li><li><span><a href=\"#7.3-Easom-Function\" data-toc-modified-id=\"7.3-Easom-Function-11\">7.3 Easom Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.3.1-Data-Profiles\" data-toc-modified-id=\"7.3.1-Data-Profiles-11.1\">7.3.1 Data Profiles</a></span></li><li><span><a href=\"#7.3.2-Deviation-Profiles\" data-toc-modified-id=\"7.3.2-Deviation-Profiles-11.2\">7.3.2 Deviation Profiles</a></span></li></ul></li><li><span><a href=\"#8.-Critical-Assessment\" data-toc-modified-id=\"8.-Critical-Assessment-12\">8. Critical Assessment</a></span></li><li><span><a href=\"#9.-Extension:-Economic-Application\" data-toc-modified-id=\"9.-Extension:-Economic-Application-13\">9. Extension: Economic Application</a></span><ul class=\"toc-item\"><li><span><a href=\"#9.1-Results:-Data-Profiles\" data-toc-modified-id=\"9.1-Results:-Data-Profiles-13.1\">9.1 Results: Data-Profiles</a></span></li></ul></li><li><span><a href=\"#10.-Conclusion\" data-toc-modified-id=\"10.-Conclusion-14\">10. Conclusion</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-15\">References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Goal of our project \n",
    "---\n",
    "\n",
    "The goal of our project was to benchmark multiple global optimization algorithms from the **NLOPT** libary. This part of our work mostly replicates work done in Gueven et al. (2019). We wanted to extend on their article by implementing our own optimization algorithms and compare them to the ones provided by the python libaries. Sadly we struggled to implement them flexible and robust enough to run the benchmarks designed for the algorithms from the **NLOPT** libary. In a future project that extend our work one could try to further improve the two algorithms we implemented but for now we decided to benchmark them with a second benchmark routine. While we can thus not compare them directly to the algorithms from the **NLOPT** libary we still get to compare the two to one another. The work we submitted to the OSE class is documented in the File student_project.ipynb . In this notebook we will mostly describe the work done in the skripts newton_based_optimization.py, nelder_mead_based_optimization.py, test_optimization.py, callable_algorithms.py and benchmark_routine.py since these were all done exclusivly by me and illustrate well how I applied routines learned in the EPPE class such as using Git, pytest and docstrings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. What is \"global optimization\"? \n",
    "---\n",
    "\n",
    "Global optimization is a term that includes many different mathematical problems of varying complexity and abstraction. Within this notebook though we want to restrict ourselfes to the unconstrained optimization of real valued functions whose domain is a open ball within $\\R^n$. We make these restrictions because the two optimization algorithms we implemented can not yet deal with any constrains and do only take open balls as domains. Clearly these restrictions make the algorithms inpractical for professional use. Since in the benchmark methodology outlined in Guvenen et al. (2019) they controll the functions to be optimized, these restrictions are reasonable. Mathematically the problems we consider can be described by the following: \n",
    "\n",
    "Let $f\\colon \\R^n \\to \\R$ be a real valued function, $r\\in\\R_+$ a positive real number and $\\mathbf{x}_\\text{d}$ be a point in $\\R^n$ such that:\n",
    "\n",
    "$$ \\underset{|x-\\mathbf{x}_\\text{d}|\\leq r}{\\text{argmin}}(f) \\in \\text{B}_r(\\mathbf{x}_\\text{d}).$$\n",
    "\n",
    "Here $\\text{B}_r(\\mathbf{x}_\\text{d})$ denotes the open circle with radius $r$ around $\\mathbf{x}_\\text{d}$.\n",
    "\n",
    "Then the algorithms should find: \n",
    "\n",
    "$$\\underset{|x-\\mathbf{x}_\\text{d}|\\leq r}{\\text{argmin}}(f).$$\n",
    "\n",
    "Since one of the two optimization algorithms we implemented relies on first and second derivatives we assume furthermore that $f$ is twice continuously differentiable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Some optimization algorithms we implemented\n",
    "---\n",
    "\n",
    "We implemented two optimization algorithms. First we implemented an algorithm that relies on the Newton-Method an algorithm that can find roots of continuously differentiable functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.1 Gradient Based algorithm\n",
    "---\n",
    "The algorithm we designed relies on the following mathematical results: \n",
    "\n",
    "\n",
    "- A continuously differentiable function has a critical point wherever it has global minimum. \n",
    "- If the newton method applied to the continuously differentiable function $f'$ converges to a point $x$ this point is a root of $f'$.\n",
    "\n",
    "\n",
    "By one we get that the set of critical points of a function is a set of candidates for the global minimum of a function. Once we have the set of critical points of $f$ within its domain we can simply take the smallest and have a good guess for the global extremum. Two provides us with a strategy to find these critical points. We can run the newton method from different starting points within the domain. Each time it converges we get a candidate that we can add to our list of candidates. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2 Derivative-Free Algorithms\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3 Algorithms Considered and Algorithm Configuration\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Test Problems\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.1 Griewank Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.2 Rastrigin Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.3 Levi Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.4 Rosenbrock Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Benchmarking Procedure\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.1 Testing of optimization Algorithms\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.2 Performing Benchmarking Experiments\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.3 Algorithm Performance Measures\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.4 Reporting Results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.5 Specific Approach of this Study\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.1 Griewank Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.1.1 Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.1.2 Deviation-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.2 Rastrigin Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.2.1 Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.2.2 Deviation-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.3 Levi Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.3.1 Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.3.2 Deviation-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.4 Rosenbrock Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.4.1 Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.4.2 Deviation-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. Extension of the Suite of Test Problems\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.1 Ackley Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.1.1 Deviation Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.2 Zakharov Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.2.2 Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.2.3 Deviation-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.3 Easom Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.3.1 Data Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.3.2 Deviation Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Critical Assessment\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 9. Extension: Economic Application\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9.1 Results: Data-Profiles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 10. Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  References\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pardalos, Panos M.; Romeijn, Edwin H., \"Handbook of Global Optimization\", Springer Science and Business Media, 2013\n",
    "- Liberti, Leo. “Introduction to Global Optimization.”, Computer Science, (2006)\n",
    "- Ali, Montaz, Charoenchai Khompatraporn, and Zelda B. Zabinsky, “A Numerical\n",
    "  Evaluation of Several Stochastic Algorithms on Selected Continuous Global Optimization\n",
    "  Test Problems,” Journal of Global Optimization, 2005, 31, 635–672.\n",
    "- Surjanovic, S. & Bingham, D. (2013). Virtual Library of Simulation Experiments: Test Functions and Datasets.     Retrieved January 4, 2022, from http://www.sfu.ca/~ssurjano.\n",
    "- Jamil, M., & Yang, X. (2013). A literature survey of benchmark functions for global optimisation problems. Int. J. Math. Model. Numer. Optimisation, 4, 150-194.\n",
    "- Griewank A.O. (1981), Generalized descent for global optimization,Journal of Optimization Theoryand Applications34, 11-39\n",
    "- Locatelli, M. A Note on the Griewank Test Function. Journal of Global Optimization 25, 169–174 (2003). https://doi.org/10.1023/A:1021956306041\n",
    "- Rosenbrock, H.H. (1960). \"An automatic method for finding the greatest or least value of a function\". The Computer Journal. 3 (3): 175–184. doi:10.1093/comjnl/3.3.175. ISSN 0010-4620.\n",
    "- J. J. More', B. S. Garbow, and K. E. Hillstrom. Testing unconstrained optimization\n",
    "   software. ACM Transactions on Mathematical Software (TOMS),7(1):17{41, March 1981\n",
    "   \n",
    "- Steven G. Johnson, The NLopt nonlinear-optimization package [link](http://github.com/stevengj/nlopt)\n",
    "- Dolan, Elizabeth D. and Jorge Moré, “Benchmarking Optimization Software with Performance\n",
    "  Profiles,” Mathematical Programming, 2002, 91 (2), 201–213.\n",
    "- Moré, Jorge J. and Stefan M. Wild, “Benchmarking Derivative-Free Optimization Algorithms,”\n",
    "  SIAM Journal on Optimization, 2009, 20 (1), 172–191.\n",
    "\n",
    "- Price, Wyn L., “A controlled random search procedure for global optimisation,” The Computer\n",
    "  Journal, 1977, 20 (4), 367–370.\n",
    "  \n",
    "- Kaelo, P. and M. M. Ali, “Some variants of the controlled random search algorithm for global\n",
    "  optimization,” Journal of Optimization Theory and Applications, 2006, 130 (2), 253–264.\n",
    "  \n",
    "- Runarsson, Thomas P. and Xin Yao, “Stochastic ranking for constrained evolutionary\n",
    "  optimization,” IEEE Transactions on evolutionary computation, 2000, 4 (3), 284–294.\n",
    "  \n",
    "- Rinnooy Kan, Alexander and G. T. Timmer, “Stochastic Global Optimization Methods,\n",
    "  Part I, Clustering Methods,” Mathematic Programming, 1987, 39 (27-56).\n",
    "  \n",
    "- Silva-Santos, Carlos Henrique, Marcos Sergio Goncalves, and Hugo Enrique\n",
    "  Hernandez-Figueroa, “Designing novel photonic devices by bio-inspired computing,” IEEE\n",
    "  Photonics Technology Letters, 2010, 22 (15), 1177–1179.\n",
    "\n",
    "- E. Atashpaz-Gargari and C. Lucas, \"Imperialist competitive algorithm: An algorithm for optimization inspired by imperialistic competition,\" 2007 IEEE Congress on   \n",
    "  Evolutionary Computation, 2007, pp. 4661-4667, doi: 10.1109/CEC.2007.4425083.\n",
    "\n",
    "- Alberto Colorni, Marco Dorigo and Vittorio Maniezzo. \"Distributed optimization by ant colonies.\" Proceedings of the first European conference on artificial life.    \n",
    "  Vol.142. 1991\n",
    "  \n",
    "- Markowitz, H. (1952), PORTFOLIO SELECTION*. The Journal of Finance, 7: 77-91. https://doi.org/10.1111/j.1540-6261.1952.tb01525.x\n",
    "\n",
    "- Eric Zivot Lecture Materials [see here](https://faculty.washington.edu/ezivot/classes.htm)\n",
    "\n",
    "- Liu, Scott and Xu, Rong, The Effects of Risk Aversion on Optimization, February 2010 (February 22, 2010). MSCI Barra Research Paper No. 2010-06, Available at SSRN: https://ssrn.com/abstract=1601412 or http://dx.doi.org/10.2139/ssrn.1601412\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
